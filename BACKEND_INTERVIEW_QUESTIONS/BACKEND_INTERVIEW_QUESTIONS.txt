Q.1 What is Caching? How can you save money with Caching?
Sol: A cache is a high-speed data storage layer which stores a subset of data, typically transient in nature, 
    so that future requests for that data are served up faster than is possible by accessing the data’s primary 
    storage location. Caching allows you to efficiently reuse previously retrieved or computed data.

    By serving web pages to your users from a local web cache, you need to fetch less data from the internet, 
    saving you bandwidth and money. Bandwidth savings translate into money in different ways in different organisations:
    i) No need to upgrade to a higher bandwidth connection
    ii) Direct cost savings on metered connections: less data traffic = lower bills
    iii) Ability to add more users without increasing capacity.

Q.2 What is load balancing?
Sol: Load balancing is the method of distributing network traffic equally across a pool of resources that support an application. 
    Modern applications must process millions of users simultaneously and return the correct text, videos, images, and other data 
    to each user in a fast and reliable manner. To handle such high volumes of traffic, most applications have many resource servers 
    with duplicate data between them. A load balancer is a device that sits between the user and the server group and acts as an 
    invisible facilitator, ensuring that all resource servers are used equally.

    Benefits of load balancing:
    i) Application availability
    ii) Application scalability
    iii) Application security
    iv) Application performance

Q.3 What is CAP Theorem?
Sol: The CAP theorem (also called Brewer’s theorem) states that a distributed database system can only guarantee two out of these 
    three characteristics: Consistency, Availability, and Partition Tolerance.
    i) Consistency: A system is said to be consistent if all nodes see the same data at the same time.
    ii) Availability: Availability in a distributed system ensures that the system remains operational 100% of the time. Every request 
        gets a (non-error) response regardless of the individual state of a node.
    iii) Partition Tolerance: This condition states that the system does not fail, regardless of if messages are dropped or delayed 
        between nodes in a system.

Q.4 What is PACELC Theorem?
Sol: The PACELC theorem states that in a system that replicates data:
    i) if there is a partition (P), a distributed system can tradeoff between availability and consistency (A or C)
    ii) else (E), when the system is running normally in the absence of partitions, the system can tradeoff between latency (L) and consistency (C).

    The first part of the theorem (PAC) is the same as the CAP theorem, and the ELC is the extension. The whole thesis assumes we 
    maintain high availability by replication. So, when there is a failure, CAP theorem prevails. But if not, we still have to consider 
    the tradeoff between consistency and latency of a replicated system.

Q.5 What is Eventual Consistency?
Sol: Eventual Consistency is a guarantee that when an update is made in a distributed database, that update will eventually be reflected in all nodes 
    that store the data, resulting in the same response every time the data is queried. With eventual consistency, results are less consistent early on, 
    but they are provided much faster with low latency. Early results of eventual consistency data queries may not have the most recent updates because 
    it takes time for updates to reach replicas across a database cluster.

Q.6 What is Strong Consistency?
Sol: Strong Consistency simply means the data must be strongly consistent at all times. All the server nodes across the world should contain the same 
    value as an entity at any point in time. And the only way to implement this behavior is by locking down the nodes when being updated. 

Q.7 What are the different types of databases?
Sol: i) Hierarchical databases: his database follows the progression of data being categorized in ranks or levels, wherein data is categorized based 
            on a common point of linkage.
    ii) Network databases:  The child records are given the freedom to associate with multiple parent records. As a result, a network or net of 
            database files linked with multiple threads is observed. 
    iii) Object-oriented databases: . Information stored in a database is capable of being represented as an object which response as an instance 
            of the database model. Therefore, the object can be referenced and called without any difficulty. 
    iv) Relational databases: In this database, every piece of information has a relationship with every other piece of information. 
            This is on account of every data value in the database having a unique identity in the form of a record.
    v) NoSQL databases: A NoSQL database includes simplicity of design, simpler horizontal scaling to clusters of machines, and finer control over 
            availability. MongoDB falls in the category of NoSQL document-based database. 

Q.8 What are message queues?
Sol: A message queue is a form of asynchronous service-to-service communication used in serverless and microservices architectures. Messages are stored 
    on the queue until they are processed and deleted. Each message is processed only once, by a single consumer. Message queues can be used to decouple 
    heavyweight processing, to buffer or batch work, and to smooth spiky workloads.

Q.9 Which service by Amazon Web Services (AWS) can you use for Queues?
Sol:Amazon Simple Queue Service (SQS) lets you send, store, and receive messages between software components at any volume, without losing messages or 
    requiring other services to be available. Use Cases:
    i) Increase application reliability and scale
    ii) Decouple microservices and process event-driven applications
    iii) Ensure work is completed cost-effectively and on time
    iv) Maintain message ordering with deduplication

Q.10 What is Pub Sub ?
Sol: Pub/Sub is an asynchronous and scalable messaging service that decouples services producing messages from services processing those messages.
    Pub/Sub allows services to communicate asynchronously, with latencies on the order of 100 milliseconds. Pub/Sub enables you to create systems of 
    event producers and consumers, called publishers and subscribers. Publishers communicate with subscribers asynchronously by broadcasting events, 
    rather than by synchronous remote procedure calls (RPCs).

Q.11 What are webhooks?
Sol: A webhook is an HTTP-based callback function that allows lightweight, event-driven communication between 2 application programming interfaces (APIs). 
    Webhooks are used by a wide variety of web apps to receive small amounts of data from other apps, but webhooks can also be used to trigger automation 
    workflows in GitOps environments.
    i) Eliminate the need for polling.
    ii) Are quick to set up.
    iii) Automate data transfer.
    iv) Are good for lightweight, specific payloads.

Q.12 What is Docker? Why do we use it?
Sol: Docker is an open source containerization platform. It enables developers to package applications into containers—standardized executable components 
    combining application source code with the operating system (OS) libraries and dependencies required to run that code in any environment. 
    We use Docker as it has enhanced the native Linux containerization capabilities with technologies that enable:
    i) Improved—and seamless—portability
    ii) Even lighter weight and more granular updates
    iii) Automated container creation
    iv) Container versioning
    v) Container reuse
    vi) Shared container libraries

Q.13 What is S3 Service in AWS?
Sol: Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. 
    Customers of all sizes and industries can use Amazon S3 to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile 
    applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides management features so that you can 
    optimize, organize, and configure access to your data to meet your specific business, organizational, and compliance requirements.

Q.14 What is EC2 Instance in AWS?
Sol: Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) Cloud. Using Amazon EC2 eliminates your need to 
    invest in hardware up front, so you can develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few virtual servers as you need, 
    configure security and networking, and manage storage. Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity, 
    reducing your need to forecast traffic.

Q.15 What is Cloudfront in AWS?
Sol: Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as . html, . css, . js, and image files, to your 
    users. CloudFront delivers your content through a worldwide network of data centers called edge locations.

Q.16 What is Route 53 in AWS?
Sol: Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service. You can use Route 53 to perform three main functions in any 
    combination: domain registration, DNS routing, and health checking.

Q.17 What are ELBs in AWS?
Sol: Elastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or 
    more Availability Zones. It monitors the health of its registered targets, and routes traffic only to the healthy targets. Elastic Load Balancing scales your 
    load balancer capacity automatically in response to changes in incoming traffic.

Q.18 What is TLS?
Sol: Transport Layer Securities (TLS) are designed to provide security at the transport layer. TLS was derived from a security protocol called Secure Socket Layer (SSL). 
    TLS ensures that no third party may eavesdrop or tampers with any message. There are several benefits of TLS: 
    i) Encryption: TLS/SSL can help to secure transmitted data using encryption.
    ii) Interoperability: TLS/SSL works with most web browsers, including Microsoft Internet Explorer and on most operating systems and web servers.
    iii) Algorithm flexibility: TLS/SSL provides operations for authentication mechanism, encryption algorithms and hashing algorithm that are used during the secure session.
    iv) Ease of Deployment: Many applications TLS/SSL temporarily on a windows server 2003 operating systems.
    v) Ease of Use: Because we implement TLS/SSL beneath the application layer, most of its operations are completely invisible to client. 

Q.19 What is the difference between https and http?
Sol: i) HTTP stands for HyperText Transfer Protocol and HTTPS stands for HyperText Transfer Protocol Secure.
    ii) In HTTP, URL begins with “http://” whereas URL starts with “https://”
    iii) HTTP uses port number 80 for communication and HTTPS uses 443
    iv) HTTP is considered to be insecure and HTTPS is secure
    v) HTTP Works at Application Layer and HTTPS works at Transport Layer
    vi) In HTTP, Encryption is absent and Encryption is present in HTTPS as discussed above
    vii) HTTP does not require any certificates and HTTPS needs SSL Certificates
    viii) HTTP speed is faster than HTTPS and HTTPS speed is slower than HTTP
    ix) HTTP does not improve search ranking while HTTPS improves search ranking.
    x) HTTP does not use data hashtags to secure data, while HTTPS will have the data before sending it and return it to its original state on the receiver side.
    xi) HTTP used to transfer the text, video, images via web pages while HTTPS used to transfer data securely via network.
    xii) HTTP is unreliable while HTTPS is reliable.
    xiii) HTTP can be Hacked but HTTPS cannot be hacked.

Q.20 What is a reverse proxy?
Sol: A reverse proxy is a server that sits in front of web servers and forwards client (e.g. web browser) requests to those web servers. Reverse proxies are typically 
    implemented to help increase security, performance, and reliability. With a reverse proxy, when clients send requests to the origin server of a website, those requests 
    are intercepted at the network edge by the reverse proxy server. The reverse proxy server will then send requests to and receive responses from the origin server.
